%\documentclass[14pt,aspectratio=169]{beamer}
\documentclass[14pt]{beamer}
\usepackage{ctex}
\usepackage{bm}
\usepackage{color, colortbl}
\definecolor{HRed}{rgb}{1,.2,.2}
%\usepackage{xeCJK} % important! Without this Chinese fonts won't show
%\usepackage{xeCJKfntef}
\setsansfont{Noto Sans CJK SC Light}
\setCJKsansfont[ItalicFont=Kaiti SC]{Noto Sans CJK SC Light}
\setCJKmainfont{Noto Serif CJK SC Light}

\usefonttheme[onlymath]{serif} % formulars in serif font
\usefonttheme{professionalfonts} % 防止公式间距异常，参见https://www.zhihu.com/question/55492768
\parskip=10pt

%\newcommand{\mat}[1]{\bm{#1}}
\newcommand{\mat}[1]{\bm{#1}}
\renewcommand{\vec}[1]{\bm{#1}}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\MA}{\mat{A}}
\newcommand{\MI}{\mat{I}}
\newcommand{\Va}{\Vec{a}}
\newcommand{\Vy}{\vec{y}}
\newcommand{\Vx}{\vec{x}}
\newcommand{\Ve}{\vec{e}}
\newcommand{\Vt}{\vec{\theta}}

\let\emph\relax % there's no \RedeclareTextFontCommand
\DeclareTextFontCommand{\emph}{\color{red}\em}
\setbeamertemplate{headline}{}
\setbeamertemplate{navigation symbols}{}
%%%%%%%%%%%%%%% Section标题页 %%%%%%%%%%%%%%%%%%%%%%%
\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
%%%%%%%%%%%%%%% 正文开始 %%%%%%%%%%%%%%%%%%%%%%%

\title{第3讲：线性回归}
\subtitle{数据分析从$y=ax+b$开始}
\author{熊耀华}
\institute{交通工程系}

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\section{线性回归基本原理}

\begin{frame}
    \frametitle{回归问题}

    \emph{回归}（Regression）是一类数据处理的理论工具，用来寻找\emph{连续变量}之间的函数规律。

    \begin{description}
        \item[变量] 一个可以变化的数字，描述自然或社会的某种现象、属性。
        \item[连续] 可以在数轴某个区间上任意取值。
    \end{description}
\end{frame}

\begin{frame}
    \frametitle{回归问题}
    以出行需求预测问题为例，对某个交通小区，令$x$表示人口、$y$表示交通出行量，我们假设两者之间存在函数关系
        \[ y = f(x) \]

    核心问题是，如何确定函数$f$。
\end{frame}

\begin{frame}
    \frametitle{线性假设}
    函数$f$理论上可以是任何形式，但那样问题过于复杂。为了方便求解，我们假设$f$是一个线性函数
    \[y=ax+b\]

    此时核心问题变成，如何确定参数$a$和$b$，也称为线性回归（Linear Regression）。
\end{frame}

\begin{frame}
    \frametitle{确定参数$a$和$b$}
    假设我们随机调查了该城市中两个小区的出行情况，结果如下
    \begin{table}
        \begin{tabular}{l c c}
            小区编号 & 人口$x$ & 出行量$y$ \\
            \hline\hline
            1   & 1000  & 20 \\
            2   & 1500  & 35 \\
            
        \end{tabular}
    \end{table}

    根据这些数据可以确定参数$a$和$b$。
\end{frame}

\begin{frame}
    \frametitle{确定参数$a$和$b$}
    根据两组调查数据，我们列出未知数$a$、$b$的方程组
    \begin{align*}
        1000a+b&=20\\
        1500a+b&=35
    \end{align*}

    求解可得$a=0.03$、$b=-10$
\end{frame}

\begin{frame}
    \frametitle{矩阵形式}
    前页中的方程组可以整理成矩阵形式
    \begin{align*}
        \begin{bmatrix}
            1000 & 1\\
            1500 & 1
        \end{bmatrix}\cdot
        \begin{bmatrix}
            a \\
            b
        \end{bmatrix}=
        \begin{bmatrix}
            20\\
            35
        \end{bmatrix}
    \end{align*}
    或者
    \[\MA\cdot \vec{\theta}=\Vy\]
    其中$\MA=\begin{bmatrix}
        \Vx & \vec{1}
    \end{bmatrix}$；$\Vx$是自变量，$\Vy$是因变量，$\Vt$是参数。
    参数$\Vt$有唯一解的前提条件是$\MA$\emph{可逆}，此时
    $\vec{\theta}= \MA^{-1}\cdot\Vy$
\end{frame}

\begin{frame}
    \frametitle{新数据带来问题}
    假如我们调查了一个新的小区
    \begin{table}
        \begin{tabular}{l c c}
            小区编号 & 人口$x$ & 出行量$y$ \\
            \hline\hline
            1   & 1000  & 20 \\
            2   & 1500  & 35 \\
            \rowcolor{HRed} 3 & 1200 & 30      
        \end{tabular}
    \end{table}

    新数据给拟合带来困难。
\end{frame}

\begin{frame}
    \frametitle{新数据带来问题}
    \label{fr:three_zones}
    此时方程变为
    \begin{align*}
        \begin{bmatrix}
            1000 & 1\\
            1500 & 1\\
            1200 & 1\\
        \end{bmatrix}\cdot
        \begin{bmatrix}
            a \\
            b
        \end{bmatrix}=
        \begin{bmatrix}
            20\\
            35\\
            30
        \end{bmatrix}
    \end{align*}

    $\vec{\theta}=
    \begin{bmatrix}
        a & b
    \end{bmatrix}^T$没有解，因为
    \[
        \MA=    
        \begin{bmatrix}
            1000 & 1\\
            1500 & 1\\
            1200 & 1\\
        \end{bmatrix}
        \]
    中约束的数量大于未知数的数量，\emph{不可逆}。
    \end{frame}

    \begin{frame}
        \frametitle{寻找最佳拟合}
        对于3组数据我们无法找到完美拟合的参数$\vec{\theta}$，我们退求其次
        寻找\emph{最佳}拟合$\vec{\theta}^*$。
        
        如何定义最佳？残差的平方和最小。
        \begin{description}
            \item[残差] 观测值和预测值之差。观测值为$\Vy$，对给定参数$\vec{\theta}$预测值为$\MA\cdot\vec{\theta}$，因此残差为$\Ve=\Vy-\MA\cdot\vec{\theta}$ 
            \item[平方和] 求和可以得到总体误差；取平方可以避免正负抵消。 
        \end{description}
    \end{frame}

    \begin{frame}
        \frametitle{平方和的内积形式}
        平方和可以缩写成向量内积形式
        \begin{align*}
            \sum_{i=1}^n e_i^2&= e_1e_1+e_2e_2+\cdots\\
                    &=\begin{bmatrix}
                        e_1 & e_2 & \cdots
                    \end{bmatrix}\cdot
                    \begin{bmatrix}
                        e_1\\
                        e_2\\
                        \vdots
                    \end{bmatrix}\\
                    &=\Ve^T\cdot\Ve
        \end{align*}
    \end{frame}

    \begin{frame}
        \frametitle{损失函数}
        基于以上分析，直线拟合问题转化为最优化问题，
        $\vec{\theta}$取什么值时$L(\theta)=\Ve^T\Ve$最小，这个最小值记为。
        \begin{equation} \label{eq:least_square}
            L^*=\min_{\vec{\theta}} L(\vec{\theta})
        \end{equation}
        函数$L$代表数据与模型的偏离程度，因此称为\emph{损失函数}（Loss Function）。
    \end{frame}
    
    \begin{frame}
        \frametitle{最小二乘法}
        这个最优参数记为$\vec{\theta}^*$
        \begin{equation}
            \vec{\theta}^*=\argmin L(\vec{\theta})
        \end{equation}
        由于$L(\vec{\theta})$是残差的平方和，这个问题又叫平方和最小问题（Least Square），
        常翻译为\emph{最小二乘}问题。
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        根据第\ref{fr:three_zones}页的数据求参数$\Vt$
    \end{frame}
    \begin{frame}
        \frametitle{取偏导数}
        将$\Ve=\MA\vec{\theta}-\Vy$代入公式\ref{eq:least_square}有
        \begin{equation}
            \begin{split}
                L(\vec{\theta})&=\Ve^T\Ve\\
                &={(\MA\vec{\theta}-\Vy)}^T(\MA\vec{\theta}-\Vy)\\
                &=\vec{\theta}^T\MA^T\MA\vec{\theta}+\Vy^T\Vy-\vec{\theta}^T\MA^T\Vy-\Vy^T\MA\vec{\theta}
            \end{split}
        \end{equation}
        对$\vec{\theta}$取\emph{偏导数}有
        \begin{equation}
            \frac{\partial L(\Vt)}{\partial\Vt}=
            2\MA^T\MA\Vt-2\MA^T\Vy
        \end{equation}
    \end{frame}

    \begin{frame}
        \frametitle{偏导数等于$0$}
        根据连续函数的性质，当$L(\Vt)$取最小值时偏导数为$0$，有
        \begin{equation}
            \frac{\partial L(\Vt)}{\partial\Vt}\bigg|_{\Vt^*}=
            2\MA^T\MA\Vt^*-2\MA^T\Vy=0
        \end{equation}
        整理右侧两项，得到线性方程
        \begin{equation}\label{eq:ls_solution}
            \MA^T\MA\Vt^*=\MA^T\Vy
        \end{equation}
    \end{frame}

    \begin{frame}
        \frametitle{新方程的性质}
        通过等式\ref{eq:ls_solution}我们得到了最小二乘法的\emph{解析解}
        \begin{equation}
            \Vt^*=(\MA^T\MA)^{-1}\MA^T\Vy
        \end{equation}
        这个结果有以下几点值得注意：
        \begin{itemize}
            \item 只有极少数最优化问题存在用简单公式表示的解析解，多数问题只能求\emph{数值解}。
            \item 方程左侧的矩阵$\MA^T\MA$是正方形矩阵，绝大多数情况下可逆。
            \item $\MA^T\MA$是\emph{对称矩阵}(试证明)，具有非常良好的性质
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        根据第\ref{fr:three_zones}页的数据，利用公式\ref{eq:ls_solution}求参数$\Vt$
    \end{frame}

    \begin{frame}
        \frametitle{最小二乘法的几何解释}
        接下来我们从几何角度来加深对问题的理解。

        回到方程$\MA\Vt=\Vy$，假设$\MA$只有两列，将方程写成\emph{列向量}形式
        \begin{equation}
            \MA\cdot\Vt=\begin{bmatrix}
                \Va_1 & \Va_2
            \end{bmatrix}\cdot
            \begin{bmatrix}
                \theta_1 \\
                \theta_2 \\
            \end{bmatrix}
            =\Vy
        \end{equation}
        其中$\Va_i$表示矩阵$\MA$的第$i$列，$\theta_i$表示第$i$个参数。
    \end{frame}

    \begin{frame}
        \frametitle{空间和基向量}
        展开上式中间一项有
        \begin{equation}
            \theta_1\Va_1+\theta_2\Va_2=\Vy
        \end{equation}

        几何解释是
        \begin{itemize}
            \item 等式左侧两个向量$\Va_1$、$\Va_2$按照
            任意比例$\theta_1$、$\theta_2$组合，\emph{张开}一个平面。向量
            $\Va_1$、$\Va_2$称为平面的\emph{基向量}
            \item 等式右侧是一个向量$\Vy$
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{情况一：有唯一解}
        \begin{itemize}
            \item 当向量$\Vy$在向量$\Va_1$、$\Va_2$张开的平面上时，$\Vt$有唯一解。
            \item $\theta_1$、$\theta_2$分别是$\Vy$在$\Va_1$、$\Va_2$方向上的\emph{投影长度}
            \begin{equation}
                \theta_i = \Vy\cdot\frac{\Va_i}{\|\Va_i\|}
            \end{equation}
            其中$\|\Va_i\|=\sqrt{\Va_i^T\Va_i}$是向量$\Va$的长度。
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{情况二：有无穷个解}
        \begin{itemize}
            \item 当向量$\Vy$、$\Va_1$、$\Va_2$在同一个方向上时，$\Vt$有无穷多解。
            \item 所有解满足条件
            \begin{equation}
                \theta_1\|\Va_1\|+\theta_1\|\Va_1\|=\|\Vy\|
            \end{equation}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{情况三：无解，构造近似问题}
        \begin{itemize}
            \item 当向量$\Vy$在向量$\Va_1$、$\Va_2$张开的平面外时，$\Vt$无解。
            \item 此时\emph{核心思路}是，我们可以在平面上挑选最\emph{接近}$\Vy$的向量$\Vy^*$。
            方程$\MA\Vt=\Vy^*$属于情况一、二，保证有解。
            \item 最小二乘法选取$\Vy$在平面上的投影作为$\Vy^*$。
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{从投影到最小二乘法}
        令投影点$\Vy^*$到$\Vy$之间的向量为$\Ve$，有$\Vy^*+\Ve=\Vy$，或者
        \begin{equation}
            \Ve=\Vy-\Vy^*
        \end{equation}
        由于$\Vy^*=\MA\Vt^*$，$\Ve$正好是\emph{残差}。

        同时由于投影的定义，我们知道$\Ve$\emph{垂直}与平面，也垂直于平面中的任意一个向量，
        例如$\Va_1$、$\Va_2$
        \begin{equation}
            \Va_1^T\cdot\Ve=0 \qquad \Va_2^T\cdot\Ve=0
        \end{equation}
    \end{frame}
    
    \begin{frame}
        \frametitle{从投影到最小二乘法}
        将两个等式重叠起来有
        \begin{equation}
            \begin{bmatrix}
                \Va_1^T\\
                \Va_2^T
            \end{bmatrix}\cdot
            \Ve=\begin{bmatrix}
                0\\
                0
            \end{bmatrix}=
            \MA^T\cdot \Ve
        \end{equation}
        带入$\Ve=\Vy-\MA\Vt^*$有
        \begin{equation}
            \MA^T(\Vy-\MA\Vt^*)=\vec{}
        \end{equation}
        展开有
        \[ \boxed{\MA^T\MA\Vt^*=\MA^T\Vy} \]
        正好是最小二乘法的解析解！
    \end{frame}

    \section{线性回归的扩展形式}

    \begin{frame}
        \frametitle{多元线性回归}
        前面的例子假设出行量$\Vy$只有一个影响因素，人口$\Vx$；实际上还可能有其他因素，例如
        平均收入。
        
        此时问题转化为\emph{多元}线性回归
        \begin{equation}
            \Vy = a\cdot\Vx_1+b\cdot\Vx_2+c\cdot\vec{1}
        \end{equation}
    \end{frame}

    \begin{frame}
        \frametitle{多元线性回归}
        方程组可以写成相同的矩阵形式
        \begin{equation}
            \MA\cdot\Vt=\Vy
        \end{equation}
        
        只是此时$\MA=\begin{bmatrix}
                \Vx_1 & \Vx_2 & \vec{1}
            \end{bmatrix}$
            ，$\Vt=\begin{bmatrix}a&b&c\end{bmatrix}^T$

        对于更多自变量的情况可以依此类推。
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        求解一个二元线性回归
    \end{frame}

    \begin{frame}
        \frametitle{多项式回归}
        对于某些数据，自变量和因变量明显不在一条直线上，用直线拟合效果肯定不佳。
        此时我们可以用\emph{多项式}曲线来拟合。

        这里看一个二次多项式，也就是抛物线的例子。
        \begin{equation}
            \Vy = a\Vx^2+b\Vx+c\vec{1}
        \end{equation}
    \end{frame}

    \begin{frame}
        \frametitle{多项式回归}
        方程组可以写成相同的矩阵形式
        \begin{equation}
            \MA\cdot\Vt=\Vy
        \end{equation}
        
        只是此时$\MA=\begin{bmatrix}
                \Vx^2 & \Vx & \vec{1}
            \end{bmatrix}$
            ，$\Vt=\begin{bmatrix}a&b&c\end{bmatrix}^T$

        对于更高次多项式可以依此类推。
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        求解一个三次多项式回归
    \end{frame}

    \section{数据模型评价}

    \begin{frame}
        \frametitle{拟合程度指标}
        通过比较回归模型的\emph{预测值}和\emph{观测值}可以评价模型的质量。
        \begin{description}
            \item[预测值] 给定自变量$\Vx$和参数$\Vt$，根据模型计算得到的因变量值，例如
            $\hat{\Vy}=a\Vx+b$。 $\hat{\Vy}$读作y-hat。
            \item[观测值] 给定自变量时实际观察到的因变量值$\Vy$，又称为参考值。 
        \end{description}
    \end{frame}

    \begin{frame}
        \frametitle{均方差}
        根据预测值和观测值可以计算\emph{均方差}（Mean Sqaure Error缩写MSE）。
        \[\text{MSE}=\frac{\Ve^T\Ve}{n}=\left(\sum_{i=1}^{n}e_i^2\right)/n
         \qquad \Ve=\hat{\Vy}-\Vy\]
        其中$n$是数据点的数量。

        MSE越小，数据拟合越好。$\text{MSE}$为$0$时数据与模型完美拟合。
    \end{frame}

    \begin{frame}
        \frametitle{自由度}
        对于$n$个数据点，我们可以构造$n-1$次多项式。此时$\MA$是$n$行$n$列的正方形矩阵，
        且$\MA$一般可逆。此时$\Vt$有唯一解，残差为$0$实现完美拟合。

        例如，对于不共线的三个数据点，直线无法完美拟合，抛物线可以。因为抛物线有更多的
        参数可以调整，可以表示的线条种类更多，具有更大的\emph{自由度}。
    \end{frame}

    \begin{frame}
        \frametitle{欠拟合和过拟合}
        模型质量和数据拟合程度并不等价。数据中往往包含内在\emph{规律}和随机\emph{噪音}两种成分
        \begin{itemize}
            \item 如果$\text{MSE}$太大，模型不能很好的解释数据的规律，称为\emph{欠拟合}
            \item 反之$\text{MSE}$太小，模型不能很好的剔除随机噪声，称为\emph{过拟合}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{泛化能力}
        评价数据模型质量的核心指标是它的\emph{泛化能力}，即根据一个数据样本集构造的模型在
        \emph{全体数据}上的拟合程度。例如
        \begin{itemize}
            \item 全世界所有城市的所有交通小区构成\emph{全体数据}
            \item 成都市所有交通小区的数据，构成一个\emph{样本集}
            \item 根据成都数据构造的模型，如果能很好的预测世界上任意城市的出行，
            那么该模型有很好的泛化能力，或者\emph{迁移性}
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{如何测试评价泛化能力}
        评价模型的泛化能力，理论上需要全体数据，但实际上很难或者不可能获得。一个变通的方法是
        \begin{itemize}
            \item 将手上的数据分为两部分，分别称为\emph{训练集}和\emph{测试集}
            \item 基于训练集构造模型，确定参数
            \item 在测试集上测试拟合程度
        \end{itemize}

        这种方式本质上是用测试集代替全体数据，可以在一定程度上避免的过拟合。
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        \begin{itemize}
            \item 划分训练集和测试集
            \item 在训练集上构造不同自由度的模型
            \item 在测试集上测试各自的泛化能力
        \end{itemize}
    \end{frame}

    \begin{frame}
        \frametitle{改进过拟合模型}
        测试发现模型过拟合说明模型的自由度过大，解决方法有
        \begin{itemize}
            \item 减少参数数量
            \item 约束参数取值范围
        \end{itemize}
        第二种方法称为\emph{正则化}（Regularization）。
    \end{frame}

    \begin{frame}
        \frametitle{Ridge Regression}
        线性回归有多种正则化形式，最常见的可能是Ridge Regression。损失函数定义为
        \begin{equation}
            L(\Vt)=\Ve^T\Ve+{\color{red}\frac{1}{2}\lambda\Vt^T\Vt}
        \end{equation}
        其中$\Vt^T\Vt$是所有参数$\Vt$的平方和，$\lambda$
        表示参数平方和的相对重要性

        这个损失函数要求在残差平方和$\Ve^T\Ve$最小的基础上让参数的平方和也尽量小。
    \end{frame}

    \begin{frame}
        \frametitle{Ridge Regression解析解}
        使用同样的分析方法，求解偏导数等于$\vec{0}$的方程
        \begin{equation}
            \frac{\partial L(\Vt)}{\partial\Vt}\bigg|_{\Vt^*}=\vec{0}
        \end{equation}
        可以得到最优参数的解析解
        \begin{equation}
            (\MA^T\MA+{\color{red}\lambda\MI})\Vt=\MA^T\Vy
        \end{equation}

        $\lambda\MI$抬高了$\MA^T\MA$矩阵对角线上的值，看起来像\emph{山脊}（Ridge）
    \end{frame}

    \begin{frame}
        \frametitle{练习}
        使用大小不同的$\lambda$拟合数据，总结规律。
    \end{frame}
\end{document}