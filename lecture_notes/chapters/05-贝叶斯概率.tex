\chapter{贝叶斯概率}

前面的章节我们介绍了最基本的数据模型——线性模型。
从中可以发现数据处理的主要复杂性在于处理噪音和误差；如果没有噪音和误差数据和模型应该完美吻合，不需要线性回归求近似解。噪音和误差本质上都是不确定性，而量化不确定性最有效的数学工具是概率论，因此我们需要补充数据处理的概率论基础。

\section{什么是概率}
概率论的研究对象自然是\emph{概率}，但关于概率的定义历史上有过很长时间的争论，一直到今天都存在两种互相竞争的定义，分别称为\emph{基于频率的概率}和\emph{贝叶斯概率}。用一句话总结
\begin{itemize}
    \item 前者认为概率是重复实验中\emph{频率}的极限；
    \item 后者认为概率是$0$到$1$之间的实数，代表命题的不确定性大小。
\end{itemize}
表面上看起来两个定义区别不大，毕竟频率也是$0$到$1$之间的实数，但实际上他们背后隐含了非常不同的哲学思考。

\subsection{频率和概率}

频率的定义来自于重复实验。假设某种试验一共有$M$种可能的结果，分别用自然数$i\in\{1,2,\cdots, M\}$表示。重复将试验进行$N$次，结果为$i$的次数记为$n_i$，结果$i$出现的\emph{频率（frequency）}记为
\begin{equation}
    f_i=\frac{N_i}{N}。
\end{equation}

由于每次试验的结果随机，因此试验总次数$N$不同时频率$f_i$也不同，但是概率论的一个基本假设是，随着试验重复次数$N$趋于无穷大，频率$f_i$会收敛于一个确定值
\begin{equation}
    p_i=\lim_{N\to\infty}f_i=\lim_{N\to\infty}\frac{n_i}{N}，
\end{equation}
这个值就是结果$i$的\emph{概率（probability）}。

基于频率的概率定义最大的优势是客观性——整个定义中涉及的要素，无论是重复试验还是结果计数都是客观存在的。
因为这个优点在很长时间内基于频率的概率都是概率论研究中的主流。
但是这个定义应用到实际问题中有一个概念上的困难，那就是对于很多问题我们因为种种原因无法进行重复试验。

\subsection{贝叶斯概率}
