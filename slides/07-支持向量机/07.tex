%\documentclass[14pt,aspectratio=169]{beamer}
\documentclass[14pt]{beamer}
\input{../preamble.tex}

%%%%%%%%%%%%%%% Section标题页 %%%%%%%%%%%%%%%%%%%%%%%
\AtBeginSection[]{
  \begin{frame}
  \vfill
  \centering
  \begin{beamercolorbox}[sep=8pt,center,shadow=true]{title}
    \usebeamerfont{title}\insertsectionhead\par%
  \end{beamercolorbox}
  \vfill
  \end{frame}
}
%%%%%%%%%%%%%%% 正文开始 %%%%%%%%%%%%%%%%%%%%%%%

\title{第7讲：支持向量机}
\subtitle{带约束的最优化问题}
\author{熊耀华}
\institute{交通工程系}

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
  \frametitle{Logistic回归与支持向量机}

  支持向量机（Support Vector Machine）和Logistic回归一样，是常见的分类模型。两者的思路也类似。

  Logistic回归模型分为两步
  \begin{description}
    \item[打分] 用一个线性函数将自变量$\Vx$映射成分数$s=\Vw^T\Vx+b$
    \item[分类] 用Logsitic函数$\sigma$将分数$s$映射成隶属概率$p=\sigma(s)$
  \end{description}

  支持向量机采用了不同的分类方式
\end{frame}

\begin{frame}
  \frametitle{支持向量机的分类方式}
  支持向量机规定，对于数据$\Vx_i$，分数
  \[s_i=\Vw^T\Vx+b\]
  分类直接由分数决定
  \[t_i=\left\{\begin{array}{rl}
    1 & \text{当}s_i\ge 1\\
    -1 & \text{当}s_i\le -1\\
  \end{array}\right.
  \]
  因变量$t_i$的两个取值$\{-1,1\}$分别代表两个类别。
\end{frame}

\begin{frame}
  \frametitle{参数$\Vw$的约束条件}
  对于$m$个数据点构成的训练集
  $$\{(\Vx_i,t_i):i=1,\ldots,m\}$$
  为保证模型与数据吻合，参数$\Vw$必须满足以下\emph{约束}
  \begin{equation}\left.
    \begin{array}{ll}
    \Vw^T\Vx_i+b\ge1 & \text{当}t_i=1\\
    \Vw^T\Vx_i+b\le-1 & \text{当}t_i=-1
    \end{array}\right\}\quad\text{对所有$i$成立}
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{约束条件的缩写}
  参数$\Vw$约束条件的两种情况可以缩写成一个公式
  \begin{equation}
    t_i(\Vw^T\Vx_i+b)\ge1\quad\text{对所有$i$成立}
  \end{equation}

  注意：这个缩写成立的关键在于两个类别用$\{-1,1\}$表示；
  如果用$\{0,1\}$则不成立。
\end{frame}

\begin{frame}
  \frametitle{最优参数}
  满足上述约束条件的参数$\Vw$很可能有多个，需要选出\emph{最优}的一个。SVM的最优标准是$\|\Vw\|$最小，得到带约束的最优化问题
  \begin{equation}
    \begin{aligned}
    &\min_{\Vw,b} \|\Vw\|\\
    \text{满足}&\\
    &t_i(\Vw^T\Vx_i+b)\ge1\quad\text{$i=1,\ldots,m$}
  \end{aligned}
\end{equation}
\end{frame}

\begin{frame}
  \frametitle{$\Vw$最小的意义}
  给定具体参数$\Vw,b$后，SVM模型把数据空间$\Vx$分成三个部分
  \begin{description}
    \item[第一类] $\Vw^T\Vx+b\ge1$ 
    \item[第二类] $\Vw^T\Vx+b\le-1$ 
    \item[\emph{边界区}] $-1<\Vw^T\Vx+b<1$ 
  \end{description}

  边界区的宽度由$\|\Vw\|$控制，$\|\Vw\|$越小边界区越宽。
\end{frame}

\begin{frame}
  \frametitle{线性不可分}
  支持向量机试图用一条直线将两类数据点分开，但是数据点的某些排布方式线性
  不可分（举例）。

  此时有两个解决思路：
  \begin{description}
    \item[软边界] 取消约束条件，代之以目标函数中的\emph{损失项}。允许少量的
    数据点处于边界的另一侧。
    \item[核方法] 用核函数（kernel function）将数据点\emph{映射}到高维空间，
    再进行分类。 
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{软边界的损失项}
  对某个数据$(\Vx_i, t_i)$，损失项可以定义为
  \begin{equation}
    l_i(\Vw, b)=\max(0, 1-t_i(\Vw^T\Vx_i+b))
  \end{equation}
  约束满足时$t_i(\Vw^T\Vx_i+b)\ge1$，此时$l_i=0$；
  不满足时$t_i(\Vw^T\Vx_i+b)<1$，此时$l_i=1-t_i(\Vw^T\Vx_i+b)>0$

  损失项可以对不满足约束的情况进行\emph{惩罚}
\end{frame}

\begin{frame}
  \frametitle{软边界的损失函数}
  基于以上分析，软边界问题需要优化以下损失函数
  \begin{equation}
    L(\Vw,b)=\frac{1}{2}\|\Vw\|^2+\lambda\sum_{i=1}^{m}\max(0, 1-t_i(\Vw^T\Vx_i+b))
  \end{equation}
  此时约束条件直接整合进目标函数，因此是\emph{无约束}优化问题 
\end{frame}

\begin{frame}
  \frametitle{映射函数}
  数据点集$\{(\Vx_i, t_i):i=1,\ldots,m\}$如果线性不可分，可以映射到高维
  空间
  $$\{(\phi(\Vx_i), t_i):i=1,\ldots,m\}$$
  新集合可能线性可分。例如
  $$\phi:x\to(x, x^2)$$
  此时\emph{原空间}中的分类边界不再是直线。
\end{frame}

\begin{frame}
  \frametitle{优化问题的求解}
  对支持向量机的最优化问题可以直接求解，也可以转化为\emph{对偶问题}再求解。

  为约束引入拉格朗日变量$\lambda_i$，目标函数变为
  \begin{equation}
    L(\Vw,b,\vec{\lambda})=\frac{1}{2}\Vw^T\Vw+\sum_{i=1}^{m}\lambda_i[1-t_i(\Vw^T\Vx_i+b)]
  \end{equation}
  通过变量替换，得到对偶问题
\end{frame}

\begin{frame}
  \frametitle{对偶问题}
  \begin{equation}
    \begin{aligned}
    &\max_{\vec{\lambda}} \left(\sum_{i=1}^{m}\lambda_i-
    \frac{1}{2}\sum_i\sum_j\lambda_i\lambda_jt_it_j\Vx_i^T\Vx_j\right)\\
    \text{满足}&\\
    &\sum_{i=1}^{m}\lambda_it_i=0,\\
    &\lambda_i\ge0
  \end{aligned}
\end{equation}
  注意，此时$\vec{\lambda}$是自变量。

\end{frame}

\begin{frame}
  \frametitle{核函数}
  \[
  \max_{\vec{\lambda}} \left(\sum_{i=1}^{m}\lambda_i-
    \frac{1}{2}\sum_i\sum_j\lambda_i\lambda_jt_it_j{\color{red}\phi(\Vx_i)^T\phi(\Vx_j)}\right)
  \]
\end{frame}
\end{document}